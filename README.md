# RAG Chatbot â€“ Flask â€¢ LangChain â€¢ Gemini â€¢ Docker â€¢ AWS

An end-to-end Retrieval-Augmented Generation (RAG) chatbot built using Flask, LangChain, Google Gemini, and HuggingFace embeddings, deployed using Docker and AWS (ECR + EC2).

This chatbot allows users to ask questions based on uploaded PDF documents and get accurate, context-aware answers.

ğŸš€ Features

ğŸ“„ PDF document ingestion

ğŸ” Semantic search using vector embeddings

ğŸ§  Context-aware answers using RAG

ğŸ’¬ Conversational memory support

ğŸ¨ Clean and modern chat UI

ğŸ³ Dockerized application

â˜ï¸ CI/CD pipeline using GitHub Actions

ğŸš€ Deployment on AWS EC2 via Amazon ECR

ğŸ› ï¸ Tech Stack

Backend

Python

Flask

LangChain

Google Gemini API

HuggingFace Embeddings

Pinecone / Vector Store (if enabled)

Frontend

HTML

CSS (custom modern UI)

Jinja2 Templates

DevOps

Docker

GitHub Actions (CI/CD)

AWS EC2

Amazon ECR

ğŸ“‚ Project Structure
rag-chatbot/
â”‚
â”œâ”€â”€ app.py                  # Flask app entry point
â”œâ”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ data/                   # PDF documents
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py           # PDF loading & preprocessing
â”‚   â”œâ”€â”€ store_index.py      # Vector store & embeddings
â”‚   â”œâ”€â”€ prompt.py           # Prompt templates
â”‚   â”œâ”€â”€ memory.py           # Conversation memory
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Chat UI
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css           # Styling
â”‚
â”œâ”€â”€ research/
â”‚   â””â”€â”€ trials.ipynb        # Experimentation notebook
â”‚
â””â”€â”€ .github/workflows/
    â””â”€â”€ cicd.yaml           # CI/CD pipeline

âš™ï¸ Installation & Setup (Local)
1ï¸âƒ£ Clone the Repository
git clone https://github.com/KingDivy/rag-chatbot.git
cd rag-chatbot

2ï¸âƒ£ Create Virtual Environment (Optional)
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Environment Variables

Create a .env file:

GOOGLE_API_KEY=your_gemini_api_key

5ï¸âƒ£ Run the App
python app.py


Open browser:

http://localhost:5000

ğŸ³ Docker Setup
Build Image
docker build -t rag-chatbot .

Run Container
docker run -d -p 5000:5000 rag-chatbot


Access:

http://localhost:5000

â˜ï¸ AWS Deployment (EC2 + ECR)

Docker image is built and pushed to Amazon ECR

EC2 pulls the image and runs the container

CI/CD automated using GitHub Actions

Ensure:

EC2 security group allows port 5000 (or 80)

Flask runs with host="0.0.0.0"

app.run(host="0.0.0.0", port=5000)

ğŸ”„ CI/CD Pipeline

Triggered on every push to main:

Build Docker image

Push image to Amazon ECR

Deploy container on EC2

Workflow file:

.github/workflows/cicd.yaml

ğŸ“¸ Screenshots

(Add UI screenshots here once ready)

ğŸ§  Future Improvements

ğŸ” Authentication

ğŸ“¤ File upload via UI

ğŸ“Š Chat history persistence

ğŸŒ Multi-document support

âš¡ Streaming responses

ğŸ‘¤ Author

Divy Desai
GitHub: @KingDivy

ğŸ“„ License

This project is licensed under the MIT License.
